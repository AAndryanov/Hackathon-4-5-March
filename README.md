# Автоматический мониторинг качества модели через дашборд

## О проекте

Этот репозиторий содержит решение команды **Just Progers** для хакатона HSE 2025 (Трек 1). Наша задача — создать инструмент автоматического мониторинга качества работы RAG-бота с помощью системы метрик и дашборда.

Разработанная система позволяет в режиме реального времени отслеживать качество извлеченных контекстов и сгенерированных ответов. Это помогает команде быстро выявлять проблемы как в самой модели, так и в базе знаний.

## Участники

- Арсений Андриянов
- Александр Федоряко
- Артем Линник
- Юрий Магус
- Иван Клочков
- Дмитрий Цирулев

---

## Проблема

Современные RAG-боты активно используются в образовательной среде, но на текущий момент отсутствуют удобные инструменты для **автоматического мониторинга** их качества. Чаще всего оценка качества происходит либо вручную, либо разово при тестировании. 

Это приводит к тому, что деградация модели (например, из-за обновления базы знаний) может оставаться незамеченной долгое время.

---

## Цель проекта

Разработать **систему мониторинга**, которая:

- автоматически обрабатывает логи работы чат-бота,
- рассчитывает набор метрик качества,
- визуализирует динамику метрик в дашборде.

## Архитектура решения

### Основные этапы

1. **Парсинг данных**
   - Обработка логов сессий (вопрос, контексты, ответ, эталон).
   - Очистка текста и подготовка данных к расчету.

2. **Расчет метрик**
   - Использование библиотеки Hugging Face Evaluate.
   - Подсчет метрик для оценки полноты и точности контекстов, а также качества ответа.

3. **Валидация**
   - Класс `ValidatorSimple` выполняет расчет метрик для каждого диалога в датасете.

4. **Визуализация**
   - Дашборд на основе Plotly/Dash отображает динамику метрик в реальном времени.

---

## Используемые метрики

### 1. Context Recall
Оценка полноты контекста — насколько выбранные ботом контексты покрывают эталонный ответ.

- Рассчитывается с помощью **ROUGE-2 (F1)**.
- Сравниваются все выбранные контексты с эталонным ответом.

### 2. Context Precision
Оценка точности контекста — насколько выбранные контексты содержат только релевантную информацию.

- Рассчитывается с помощью **BLEU-2**.
- Сравниваются все выбранные контексты с эталонным ответом.

### 3. Answer Correctness (Literal)
Лексическая корректность ответа — насколько текст ответа близок к эталону по словам и символам.

- Рассчитывается с помощью **chrF**.

### 4. Answer Correctness (Neural)
Семантическая корректность ответа — насколько ответ модели совпадает с эталоном по смыслу.

- Рассчитывается с помощью **BertScore**.
- Требует GPU для быстрой работы.

### 5. The best nerwork
Эта метрика определяет, какая из нейросетей чаще дает ответы, которые понравились пользователям. 

 - Считается как отношение положительных ответов к их общему числу.

### 6. Проблемные категории 
Метрика показывает, на вопросы какой категории требовалось больше всего уточнений.

---

## Структура репозитория

| Файл | Описание |
|---|---|
| `func_to_call.py` | Функции для обработки данных и логов. |
| `metrics.py` | Реализация всех метрик, используемых в проекте. |
| `ValidatorSimple` | Класс для валидации и расчета метрик на тестовом датасете. |
| `train_set.json` и `val_set.json` | Тестовые данные с диалогами, контекстами и эталонными ответами. |
| `test.ipynb` | Jupyter Notebook с примером работы системы и расчетом метрик. |

---

## Дашборд

Дашборд состоит из 5 вкладок:

- Общая статистика по всем данным.
- Отдельные вкладки по каждому кампусу: Москва, Нижний Новгород, Санкт-Петербург, Пермь.

### Что показывается на дашборде

- Графики: динамика метрик `context_recall`, `answer_correctness`.
- Таблицы: сводные значения метрик по всем сессиям.
- Фильтры: выбор временного интервала для анализа.

### Обновление данных
- Для симуляции работы с реальными логами дашборд обновляется каждые 3 секунды, добавляя случайную строку из тестового датасета.

---

## Технологии

| Компонент | Технологии |
|---|---|
| Метрики | Hugging Face Evaluate (rouge, bleu, chrf, bertscore) |
| Обработка данных | Python (pandas, numpy, tqdm) |
| Визуализация | Plotly / Dash |
| Логи | JSON-файлы (структура вопросов, ответов и контекстов) |

---

## Как запустить

1. Установить зависимости:
    ```bash
    pip install -r requirements.txt
    ```

2. Запустить обработку данных и расчет метрик:
    ```bash
    python main.py
    ```

3. Запустить дашборд (если вынесен в отдельный скрипт):
    ```bash
    python dashboard.py
    ```

---

## Почему наше решение эффективно

- Простая интеграция в существующий стек RAG-бота — достаточно сохранять логи с вопросами, контекстами и ответами.
- Полное покрытие всех ключевых аспектов качества: от полноты выборки до качества генерации.
- Автоматическое обновление метрик и визуализация в реальном времени.
- Гибкость в масштабировании — систему можно адаптировать под любого чат-бота с аналогичной архитектурой.

---

## Возможные доработки

- Добавить метрики user feedback (индекс доверия и фрустрации).
- Добавить оценку релевантности контекстов через ранжирование.
- Интегрировать в CI/CD-процессы для контроля качества перед релизами.

---

## Авторы

Команда Just Progers:

- Арсений Андриянов
- Александр Федоряко
- Артем Линник
- Юрий Магус
- Иван Клочков
- Дмитрий Цирулев

---

## Лицензия

Проект создан в рамках хакатона HSE 2025 и может использоваться для образовательных целей.

---
